# Проект по предсказанию судьбы стартапов

В данном проекте мы поработали с псевдо-реальными (реальные данные в которые добавлена синтетическая составляющая) данными о стартапах, функционировавших в период с 1970 по 2018 годы. Нашей целью было и предсказать, какие из стартапов закроются, а какие останутся на плаву. Соревнование проводилось на популярной платформе Kaggle.

В качестве метрики в соревновании был выбрана F1-Score, которая является гармоническим средним между Recall и Precision.

Входные данные для реализации проекта:
- kaggle_startups_train_01.csv - информация (53 000) стартапах, которые будут использоваться в качестве обучающих данных.
- kaggle_startups_test_01.csv - информация (13 000) стартапах, которые будут использоваться в качестве тестовых данных. Ваша задача - предсказать значение 'status' для каждого стартапа из этого датасета.
- kaggle_startups_sample_submit_01.csv - файл с примером предсказаний в правильном формате.

Тренировочный набор содержит целевой признак status, указывающий на то, закрылся стартап или продолжает действовать. Временной период - '1970-01-01' по '2018-01-01'. Дата формирования выгрузки - '2018-01-01'.

__Первым шагом__, была загрузка просмотр данных. Далее проведена предобработка данных, которая включала в себя:
- проверку соответствия типов данных значений столбцов;
- анализ объема и заполнение пропущенных значений;
- проверка и устранение явных и неявных дубликатов с укрупнением некоторых категорий с множеством уникальных значений.

Далее, проведен __исследовательский анализ__. Проанализировали количественные и категориальные признаки датафреймов, оценено  количество выбросов в данных, особенно они были заметны в данных по общей сумме финансирования. Также было замечено, что большинство стартапов из нашей выборки привлекали сравнительно небольшие инвестиции по сравнению с некоторыми компаниями, которые впоследствии стали лидерами рынка. Однако таких компаний, конечно же, гораздо меньше.

![image.png](attachment:9245a4fa-7de3-413a-acc0-d850502f3f1d.png)

Кроме того, заметили явный дисбаланс классов по целевой переменной, который затем пытались устранить с помощью сэмплирования алгоритмами SMOTETomek и SMOTEENN.

Мы также обнаружили, что большинство стартапов проходит только один раунд финансирования. Это подтверждается тем, что медиана составляет единицу. Оказалось, что большинство стартапов было основано в период с 2006 по 2012 год.
Сравнив количество работающих и закрытых стартапов по различным категориям, мы увидели следующее:
* В таких областях, как биотехнологии и электронная коммерция, больше открытых стартапов;
* В сфере образования и в отраслях с неизвестными направлениями деятельности, а также в сфере технологий больше закрытых стартапов.
*
Что касается местоположения, то лидером по количеству как работающих, так и закрытых стартапов являются США. Интересно, что Россия не входит в топ-10 по количеству работающих стартапов, но занимает 4-е место по количеству закрытых стартапов.

Следующим этапом, было __создание новых синтетических признаков__, которые могли бы помочь в реализации обучения. Создали такие признаки как:

- показатель количества дней с даты основания компании до даты выгрузки, если у компании была дата закрытия, то количество дней будет считалось до даты закрытия
- создан новый столбец с lifetime для тренировочной выборки
- количество дней с первой даты финансирования до начала выгрузки
- количество дней с последней даты раунда финансирования до даты выгрузки
- признак с объединением страны и штата в один общий и т.д.

Затем, провели __корреляционный анализ__, провели наличие мультиколлинеарности между признаками, а также взаимосвязь с таргетом. Отобрали наиболее коррелирующие признаки и избавились от мультиколлинеарности.

![image.png](attachment:f252383f-3d87-465f-afeb-8401319e74a7.png)

Наиболее высокая корреляция наблюдается между целевой переменной и следующими признаками: lifetime, country_code, days_from_last_funding и enl_category. Эти признаки стали основой для обучения наших моделей, также мы оставили некоторые синтетические признаки, которые создали ранее, хоть они и имеют маленькую корреляцию с таргетом, но при обучении могут немного повысить качество модели.

Последним объемным этапом нашей работой стала __подготовка данных в пайплайне и обучение моделей машинного обучения__. Разделили обучающую выборку на обучающую и валидационную, закодировали целевую переменную с помощью LabelEncoder. Подготовили данные в пайплайне, включая кодирование и масштабирование входных признаков, а также комбинированное сэмплирование с помощью SMOTETomek и SMOTEENN для борьбы с дисбалансом классов.

Обучение и подбор гиперпараметров проводились с помощью RandomizedSearch и OptunaSearch. Сначала мы случайным образом определили наилучшую модель, в подборе участвовали модели: kNN, DecisionTreeClassifier, SVC и RandomForest, в качестве гиперпараметров искользовалась регуляризация, глубина дерева, количество ближайших соседей. Затем, используя Optuna, мы попытались найти ещё более оптимальные настройки для модели DecisionTreeClassifier с гиперпараметрами 'max_depth' и 'min_samples_split'.
```
Лучшая модель и её параметры:

 Pipeline(steps=[('columntransformer',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('pipeline',
                                                  Pipeline(steps=[('simpleImputer_ohe',
                                                                   SimpleImputer(fill_value='Unknown',
                                                                                 strategy='constant')),
                                                                  ('ohe',
                                                                   OneHotEncoder(drop='first',
                                                                                 handle_unknown='ignore',
                                                                                 sparse_output=False))]),
                                                  ['country_code',
                                                   'enl_category']),
                                                 ('minmaxscaler',
                                                  StandardScaler(),
                                                  ['funding_total_usd',
                                                   'lifetime',
                                                   'days_from_last_funding',
                                                   'first_to_last_funding',
                                                   'rounds_per_year',
                                                   'relation_lastf_to_lifetime'])])),
                ('smotetomek', SMOTEENN(random_state=42)),
                ('svc',
                 RandomForestClassifier(class_weight='balanced',
                                        random_state=42))])
Метрика f1 для лучшей модели:
 0.98408
```

Затем,  мы получили предсказания с помощью наилучших моделей на тестовой выборке и создали файлы в нужном формате и с нужным содержимым для загрузки результатов и участия в соревновании на площадке Kaggle.

После всех тестирований, лучшие оценки выглядят следующим образом:

RandomForest:

Метрика f1 для лучшей модели RandomizedSearch на валидационной выборке: 0.98414
Метрика ROC_AUC для лучшей модели RandomizedSearch на валидационной выборке: 0.91959

DecisionTreeClassifier:

Метрика f1 для лучшей модели OptunaSearch на валидационной выборке: 0.97932
Метрика ROC_AUC для лучшей модели OptunaSearch на валидационной выборке:0.91889
